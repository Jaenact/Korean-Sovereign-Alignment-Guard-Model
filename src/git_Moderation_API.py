import json
import logging
import re
import time
from collections import OrderedDict
from json import JSONDecodeError
from pathlib import Path
from typing import Dict, List, Optional

import openai
from openai import OpenAI

openai.api_key = "YOUR_API"

API_KEY = openai.api_key
MODEL_NAME = "gpt-4o-mini"
DATASET_DIR = Path(__file__).resolve().parent.parent / "Dataset"
OUTPUT_FILE = DATASET_DIR / "augmented_dataset.json"
MAX_RETRIES = 3
RETRY_BACKOFF_BASE = 2
TEMPERATURE = 0.2
CLIENT: Optional[OpenAI] = None

TEST_MODE = False
TEST_LIMIT = 5

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")


def init_client() -> OpenAI:
    global CLIENT
    if CLIENT is None:
        if not API_KEY or API_KEY == "YOUR_OPENAI_API_KEY":
            raise EnvironmentError("ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.")
        CLIENT = OpenAI(api_key=API_KEY)
    return CLIENT


def normalize_category(raw_category: str) -> str:
    rc = (raw_category or "").lower()
    
    territory_keywords = ["ë…ë„", "ì˜í† ", "ì´ì–´ë„", "nll", "dokdo", "territor"]
    distortion_keywords = ["ë™ë¶ê³µì •", "ë™ë¶ ê³µì •", "ë¬¸í™”", "ê¹€ì¹˜", "í•œë³µ", "ë°œí•´", "ê³ êµ¬ë ¤", "ë¬¸í™”ì¹¨íƒˆ"]
    humanright_keywords = ["ìœ„ì•ˆë¶€", "ì§•ìš©", "ê°•ì œ", "ê°•ì œì§•ìš©", "ê°•ì œ ì§•ìš©", "6Â·25", "6.25", "6-25", "í•œêµ­ì „ìŸ", "ì „ìŸ"]
    
    for k in territory_keywords:
        if k in rc:
            return "ì˜í†  ì£¼ê¶Œ ë¶„ìŸ"
    
    for k in distortion_keywords:
        if k in rc:
            return "ì—­ì‚¬ ì™œê³¡ ë° ë¬¸í™” ì¹¨íƒˆ"
    
    for k in humanright_keywords:
        if k in rc:
            return "ì „ìŸ ë° ì ë ¹ê¸° ì¸ê¶Œ ë¬¸ì œ"
    
    mapping = {
        "ì˜í†  ì£¼ê¶Œ ë¶„ìŸ": "ì˜í†  ì£¼ê¶Œ ë¶„ìŸ",
        "ì—­ì‚¬ ì™œê³¡ ë° ë¬¸í™” ì¹¨íƒˆ": "ì—­ì‚¬ ì™œê³¡ ë° ë¬¸í™” ì¹¨íƒˆ",
        "ì „ìŸ ë° ì ë ¹ê¸° ì¸ê¶Œ ë¬¸ì œ": "ì „ìŸ ë° ì ë ¹ê¸° ì¸ê¶Œ ë¬¸ì œ",
    }
    
    if raw_category in mapping:
        return mapping[raw_category]
    
    if any(w in rc for w in ["territor", "land", "island", "sea", "í•´", "ë…ë„", "ì´ì–´ë„"]):
        return "ì˜í†  ì£¼ê¶Œ ë¶„ìŸ"
    
    return "ì—­ì‚¬ ì™œê³¡ ë° ë¬¸í™” ì¹¨íƒˆ"


def load_dataset(path: Path) -> List[Dict[str, str]]:
    try:
        with path.open("r", encoding="utf-8") as file:
            data = json.load(file)
    except JSONDecodeError as exc:
        logging.error("JSON ë””ì½”ë”© ì‹¤íŒ¨: %s (%s)", path.name, exc)
        return []
    if not isinstance(data, list):
        logging.warning("ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹Œ íŒŒì¼ ë¬´ì‹œ: %s", path.name)
        return []
    result: List[Dict[str, str]] = []
    for item in data:
        if isinstance(item, dict):
            result.append(item)
        else:
            logging.warning("ì‚¬ì „ í˜•ì‹ì´ ì•„ë‹Œ í•­ëª© ë¬´ì‹œ: %s", path.name)
    return result


SYSTEM_PROMPT = """\
ë‹¹ì‹ ì€ ë°˜ë“œì‹œ JSON ê°ì²´ë§Œ ë°˜í™˜í•˜ëŠ” ëª¨ë¸ì´ë‹¤.
ì¶”ê°€ ì„¤ëª…, ë¶ˆí•„ìš”í•œ ë¬¸ì¥, ì£¼ì„, ì‚¬ì¡±ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤.
ì…ë ¥ì€ ë‹¤ìŒ ë‘ í•„ë“œë¥¼ í¬í•¨í•œë‹¤:
- category
- harmful_prompt
ë°˜í™˜í•  JSONì€ ë°˜ë“œì‹œ ë‹¤ìŒ ë„¤ í•„ë“œë¥¼ í¬í•¨í•´ì•¼ í•œë‹¤(í‚¤ ìˆœì„œ: category, harmful_prompt, benign_prompt, ideal_answer).
1) "category": ì…ë ¥ê³¼ ë™ì¼í•œ ë¬¸ìì—´ (ì‚¬í›„ ì²˜ë¦¬ì—ì„œ ë§ˆìŠ¤í„° ì¹´í…Œê³ ë¦¬ë¡œ êµì²´ë  ìˆ˜ ìˆìŒ)
2) "harmful_prompt": ì…ë ¥ê³¼ ë™ì¼í•œ ë¬¸ìì—´
3) "benign_prompt": harmful_promptì˜ ë¬¸ì²´(ì˜ë¬¸í˜•Â·í‰ì„œí˜•Â·ëª…ë ¹í˜• ë“±)ë¥¼ ìœ ì§€í•˜ë˜, ì¤‘ë¦½ì ì´ê³  ì‚¬ì‹¤ í™•ì¸ ì¤‘ì‹¬ì˜ ì§ˆë¬¸ ë˜ëŠ” ì§„ìˆ ë¡œ ë³€í™˜í•œë‹¤. ì •ì¹˜ì  ì£¼ì¥, ê°€ì¹˜ íŒë‹¨, íŠ¹ì • êµ­ê°€ ë¹„ë°©ì„ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤.
4) "ideal_answer": ì—­ì‚¬ì , ì§€ë¦¬ì , êµ­ì œë²•ì  ì‚¬ì‹¤ì„ ê¸°ë°˜ìœ¼ë¡œ ëŒ€í•œë¯¼êµ­ì˜ ì…ì¥ì„ ëª…í™•í•˜ê³  ë‹¨ì •ì ìœ¼ë¡œ ì„¤ëª…í•œë‹¤. ì–‘ë¹„ë¡  ë˜ëŠ” "ë…¼ìŸì˜ ì—¬ì§€ê°€ ìˆë‹¤" ê°™ì€ ëª¨í˜¸í•œ ë¬¸ì¥ì€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.
ì¶”ê°€ ê·œì¹™:
- JSON ì™¸ì˜ ë¬¸ìì—´(ì˜ˆ: ì„¤ëª… í…ìŠ¤íŠ¸)ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤.
- ë°˜í™˜ ê°’ì€ ë‹¨ì¼ JSON ê°ì²´ì—¬ì•¼ í•˜ë©° ë°°ì—´ì„ ë°˜í™˜í•˜ì§€ ì•ŠëŠ”ë‹¤.
- ë¬¸ìì—´ ë‚´ë¶€ ê°œí–‰ì€ í—ˆìš©í•˜ë‚˜, ì „ì²´ ì¶œë ¥ì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤.
- JSON í‚¤ëŠ” ì •í™•íˆ category, harmful_prompt, benign_prompt, ideal_answer ì´ì—¬ì•¼ í•œë‹¤.
"""

USER_PROMPT_TEMPLATE = (
    "ì•„ë˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ìœ„ ì‹œìŠ¤í…œ ì§€ì¹¨ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ëŠ” JSON ê°ì²´ë¥¼ ìƒì„±í•˜ë¼.\n\n"
    "ì…ë ¥:\n"
    "category: {category}\n"
    "harmful_prompt: {harmful_prompt}\n\n"
    "ì¶œë ¥ì€ ì˜¤ì§ JSON ê°ì²´ í•˜ë‚˜ë¡œë§Œ ë°˜í™˜í•˜ë¼."
)


def safe_extract_json(text: str) -> Optional[Dict]:
    text = text.strip()
    
    try:
        return json.loads(text)
    except JSONDecodeError:
        pass
    
    first = text.find("{")
    last = text.rfind("}")
    if first != -1 and last != -1 and last > first:
        candidate = text[first : last + 1]
        try:
            return json.loads(candidate)
        except JSONDecodeError:
            return None
    
    return None


def generate_moderation_entry(category: str, harmful_prompt: str) -> Dict[str, str]:
    client = init_client()
    hp_safe = harmful_prompt.replace("\r", " ").replace("\n", " ").strip()
    normalized = normalize_category(category)
    user_prompt = USER_PROMPT_TEMPLATE.format(category=category, harmful_prompt=hp_safe)
    
    attempt = 0
    while attempt < MAX_RETRIES:
        attempt += 1
        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=TEMPERATURE,
                max_tokens=1000,
            )
        except (openai.APIError, openai.APIConnectionError, openai.RateLimitError, Exception) as exc:
            wait = RETRY_BACKOFF_BASE ** attempt
            logging.warning("OpenAI ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ %d/%d). %s - %s ì´ˆ í›„ ì¬ì‹œë„", attempt, MAX_RETRIES, exc, wait)
            time.sleep(wait)
            continue
        
        choice = None
        try:
            choice = response.choices[0]
        except Exception:
            logging.error("OpenAI ì‘ë‹µ í˜•ì‹ì´ ì˜ˆê¸°ì¹˜ ì•ŠìŠµë‹ˆë‹¤.")
            if attempt < MAX_RETRIES:
                time.sleep(RETRY_BACKOFF_BASE ** attempt)
                continue
            raise RuntimeError("OpenAI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨")
        
        message = getattr(choice, "message", None) or (choice.get("message") if isinstance(choice, dict) else None)
        content = ""
        if message:
            content = message.get("content") if isinstance(message, dict) else getattr(message, "content", "")
        else:
            content = getattr(choice, "text", "") or (choice.get("text", "") if isinstance(choice, dict) else "")
        
        if not content:
            logging.error("LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŒ. ì‹œë„ %d/%d", attempt, MAX_RETRIES)
            if attempt < MAX_RETRIES:
                time.sleep(RETRY_BACKOFF_BASE ** attempt)
                continue
            raise ValueError("LLM ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        payload = safe_extract_json(content)
        if not payload:
            logging.warning("LLMì—ì„œ JSON ì¶”ì¶œ ì‹¤íŒ¨ (ì‹œë„ %d/%d). ì‘ë‹µ ì¼ë¶€: %s", attempt, MAX_RETRIES, (content[:400] + "...") if len(content) > 400 else content)
            if attempt < MAX_RETRIES:
                time.sleep(RETRY_BACKOFF_BASE ** attempt)
                continue
            raise ValueError("LLM ì‘ë‹µì—ì„œ JSON ê°ì²´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        expected_keys = {"category", "harmful_prompt", "benign_prompt", "ideal_answer"}
        if not expected_keys.issubset(set(payload.keys())):
            logging.warning("LLM ë°˜í™˜ JSONì— í•„ë“œ ëˆ„ë½ (ì‹œë„ %d/%d). ëˆ„ë½: %s", attempt, MAX_RETRIES, expected_keys - set(payload.keys()))
            if attempt < MAX_RETRIES:
                time.sleep(RETRY_BACKOFF_BASE ** attempt)
                continue
            raise ValueError(f"LLM ì‘ë‹µ í•„ë“œ ëˆ„ë½: {expected_keys - set(payload.keys())}")
        
        returned_harmful = payload.get("harmful_prompt", "").strip()
        if returned_harmful != hp_safe:
            logging.warning("LLMì´ harmful_promptë¥¼ ë³€ê²½í•¨ (ì‹œë„ %d/%d). ì…ë ¥: %s | ë°˜í™˜: %s", attempt, MAX_RETRIES, hp_safe, returned_harmful)
            if attempt < MAX_RETRIES:
                time.sleep(RETRY_BACKOFF_BASE ** attempt)
                continue
            payload["harmful_prompt"] = hp_safe
        
        payload["category"] = normalized
        
        if not payload.get("benign_prompt") or not payload.get("ideal_answer"):
            logging.warning("LLMì´ ë¹ˆ í•„ë“œë¥¼ ë°˜í™˜í•¨ (ì‹œë„ %d/%d).", attempt, MAX_RETRIES)
            if attempt < MAX_RETRIES:
                time.sleep(RETRY_BACKOFF_BASE ** attempt)
                continue
            raise ValueError("LLM ì‘ë‹µì˜ benign_prompt ë˜ëŠ” ideal_answerê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        result = OrderedDict()
        result["category"] = normalized.strip()
        result["detail_category"] = category.strip()
        result["harmful_prompt"] = payload["harmful_prompt"].strip()
        result["benign_prompt"] = payload["benign_prompt"].strip()
        result["ideal_answer"] = payload["ideal_answer"].strip()
        
        return result
    
    raise RuntimeError("LLM ìš”ì²­/ì‘ë‹µ ì‹¤íŒ¨: ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼")


def process_dataset_file(path: Path, client: OpenAI, global_results: List[Dict[str, str]]) -> None:
    entries = load_dataset(path)
    if not entries:
        logging.warning("[%s] ì²˜ë¦¬í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.", path.name)
        return
    
    if TEST_MODE:
        entries = entries[:TEST_LIMIT]
        logging.info("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: %dê°œ í•­ëª©ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.", len(entries))
    
    total = len(entries)
    for idx, item in enumerate(entries, 1):
        category = item.get("category")
        harmful_prompt = item.get("harmful_prompt")
        if not category or not harmful_prompt:
            logging.warning("í•„ìˆ˜ í•„ë“œ ëˆ„ë½ìœ¼ë¡œ ê±´ë„ˆëœ€: %s", path.name)
            continue
        
        logging.info("[%s] í•­ëª© %d/%d ì²˜ë¦¬ ì¤‘...", path.name, idx, total)
        try:
            result = generate_moderation_entry(category, harmful_prompt)
            global_results.append(result)
            save_results(global_results, append=False)
            progress = (idx / total) * 100
            logging.info("[%s] ì§„í–‰ë¥ : %d/%d (%.1f%%) - ì €ì¥ ì™„ë£Œ", path.name, idx, total, progress)
        except Exception as exc:
            logging.error("ìƒì„± ì‹¤íŒ¨: íŒŒì¼=%s í•­ëª©=%s ì˜¤ë¥˜=%s", path.name, harmful_prompt, exc)


def collect_dataset_files() -> List[Path]:
    files: List[Path] = []
    for path in sorted(DATASET_DIR.glob("*.json")):
        if path.name == OUTPUT_FILE.name:
            continue
        files.append(path)
    return files


def load_existing_results() -> List[Dict[str, str]]:
    if OUTPUT_FILE.exists():
        try:
            with OUTPUT_FILE.open("r", encoding="utf-8") as file:
                return json.load(file)
        except (JSONDecodeError, IOError):
            return []
    return []


def save_results(data: List[Dict[str, str]], append: bool = False) -> None:
    if append:
        existing = load_existing_results()
        data = existing + data
    with OUTPUT_FILE.open("w", encoding="utf-8") as file:
        json.dump(data, file, ensure_ascii=False, indent=2)


def main() -> None:
    if not DATASET_DIR.exists():
        raise FileNotFoundError(f"Dataset ë””ë ‰í„°ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATASET_DIR}")
    
    if TEST_MODE:
        logging.info("=" * 60)
        logging.info("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ í™œì„±í™”: ì²« ë²ˆì§¸ íŒŒì¼ì—ì„œ %dê°œ í•­ëª©ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.", TEST_LIMIT)
        logging.info("=" * 60)
    
    client = init_client()
    dataset_files = collect_dataset_files()
    
    if not dataset_files:
        logging.warning("Dataset ë””ë ‰í„°ë¦¬ì— ì²˜ë¦¬í•  JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: %s", DATASET_DIR)
        return
    
    if OUTPUT_FILE.exists():
        OUTPUT_FILE.unlink()
        logging.info("ê¸°ì¡´ ì¶œë ¥ íŒŒì¼ ì‚­ì œ: %s", OUTPUT_FILE.name)
    
    global_results: List[Dict[str, str]] = []
    total_files = len(dataset_files)
    
    for file_idx, dataset_file in enumerate(dataset_files, 1):
        logging.info("=" * 60)
        logging.info("[íŒŒì¼ %d/%d] ì²˜ë¦¬ ì‹œì‘: %s", file_idx, total_files, dataset_file.name)
        logging.info("=" * 60)
        
        process_dataset_file(dataset_file, client, global_results)
        
        logging.info("[%s] íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ. í˜„ì¬ ëˆ„ì  í•­ëª© ìˆ˜: %d", dataset_file.name, len(global_results))
        
        if TEST_MODE:
            logging.info("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: %dê°œ í•­ëª© ì²˜ë¦¬ ì™„ë£Œ. í…ŒìŠ¤íŠ¸ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.", len(global_results))
        break
    
    if global_results:
        logging.info("=" * 60)
        logging.info("ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ: ì´ %dê°œ í•­ëª©ì´ %sì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", len(global_results), OUTPUT_FILE.name)
        if TEST_MODE:
            logging.info("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì „ì²´ ì‹¤í–‰ì„ ì›í•˜ë©´ TEST_MODE = Falseë¡œ ì„¤ì •í•˜ì„¸ìš”.")
        logging.info("=" * 60)
    else:
        logging.warning("ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()

